---
title: "Forecasting the Outbreak of Zika with Indirect Data Sources"
author: "Taneisha Arora, Tristan Dam"
date: "June 8, 2020"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse) # data manipulation
library(forecast) # for ts modelling
library(urca) # for unit root test
library(ggplot2) # for visualizations

# for global settings (use knitr)
knitr::opts_chunk$set(
  echo = FALSE,
  fig.align = "center",
  fig.show = TRUE
)
```


This "zika_timeseries.csv" dataset is the compliation of our data cleaning and processing. It is generated by running the "Preprocessing.R" script in this folder, however we have generated it in advance to save time.
```{r housekeeping}
# Read in dataset
forecast_df <- read_csv("../Data/zika_timeseries.csv")
```


## 1. Exploratory Data Analysis

<p>
We collected cumulative weekly case counts of the Zika Virus over the course of the years **2015, 2016, and 2017**. The case counts we collected were from the **Brazil**, the country where the first confirmed case was reported in May 2015, and the **United States**.
</p>

<p>
Our primary goal is to be able to forecast the number of Zika Cases that will be reported in the United States in the following week. In other words, using data from weeks 1 to N-1, predict the number of new cases in week N. So, our "Y" is the number of Zika cases reported in the United States in a given week. Before beginning the modelling process we will need to:
</p>

1.1 Check for Anomoulous Data Points <br>
1.2 Establish Stationarity <br>
1.3 Explore which Features could be Associated with Weekly US Zika Case Counts <br>
1.4 Determine whether there is Autocorrelation and/or Cross-correlation <br>


### 1.1 Check for Anomoulous Data Points

<p>Before deving into visualizations, we will take a look at our raw data. This is to check for any anomalyous values such as negative case counts. For this purpose we will query the `brazil_counts` and `observed` columns in our preprocessed dataset. We do not check the other fields as those were derived from our original data sources (Twitter/Reddit databases) and have, so, been preprocessed.</p>

```{r verify}
forecast_df %>%
  rowid_to_column() %>%
  filter(brazil_counts < 0 | observed < 0) %>%
  select(rowid, brazil_counts, observed) %>%
  knitr::kable()
```

<p> We see that in row 123 (which corresponds to week 123 since the data frame is ordered by week number) the number of observed cases in the United States is -38. This could either be a decrease in cases from the previous week, or simply an error. We could either impute the mean of the case counts of the previous and the next weeks, which would suggest that the number of new cases in week 123 was similart to those observed in the weeks immediately following and preceding it. Alternatively, the negative value could have arisen from a decrease in cumulative cases in week 123 relative to week 122. This interpretation suggests that the number of new cases reported in week 123 was zero</p>

<p>We will impute the negative value with the mean case count for weeks 122 and 124.</p>
```{r impute}
observations_to_impute <- c(123)

forecast_df[observations_to_impute,"observed"] <- (forecast_df[observations_to_impute-1,"observed"] + forecast_df[observations_to_impute+1,"observed"])/2
```

### 1.2 Establishing Stationarity

<p>Having scrubbed the data for any invalid values, we will now create some time series plots to visualize how the number of reported Zika cases in the United States varies over time. We will first perform a qualitative check by looking for patterns in the time series plot, followed by a more formal Unit Root test, to determine whether our data is stationary or not, and if differencing is required..</p>

```{r ts_objects}
scaled_forecast <- forecast_df %>%
  mutate_all(scale)

# Time series object
ts_obj <- ts(forecast_df, start = c(2015, 1), end = c(2017, 52) , frequency = 52)

# Time series object with scaled counts
ts_obj_scaled <- ts(scaled_forecast, start = c(2015, 1), end = c(2017, 52), frequency = 52)
```

#### 1.2.a Qualitative Scan
```{r eda_cases}
observed_vals <- forecast_df %>% 
  mutate(observed = if_else(is.na(observed), 0, observed)) 

autoplot(ts_obj[,c("observed")]) +
  xlab("Year") + 
  ylab("Case Counts Counts") +
  labs(title = "Weekly Zika Case Counts in the US, Over Time")
```

<p>We see a peak in cases a few months into 2016. The case counts decrease, progressing into 2017. Since the data does not look random at every time point, but rather shows a distinctive pattern (peak/fall), we suspect our data is **non-stationary**.</p>

#### 1.2.b Unit Root Test

<p>The high level hypotheses of the Unit Root test are:</p>

$H_0 : The\;data\;is\;stationary$ <br>
$H_a: The\;data\;is\;not\;stationary$
```{r eda_cases_us}
ur.kpss(observed_vals$observed) %>% summary()
```
<p> The test statistic, **0.4374** is **greater** than the 5% critical value, **0.463** which means that the **p-value is less than 0.05**, and we accept the alternative, that our data is **__not stationary__**.</p>

<p> Here is a visualziaion of the first differenced Weekly US case counts: </p>
```{r differneced_plot}
autoplot(diff(ts_obj_scaled[,c("observed")])) +
  xlab("Year") + 
  ylab("(Differenced) Normalized US Zika Case Counts")

```


### 1.3 Explore which Features could be Associated with Weekly US Zika Case Counts

<p> Now we will plot some of our weekly features along with the Weekly US Zika Case counts to see how certain features that follow the trend of the Zika cases reported in the US</p>

```{r cases_brazil}
autoplot(ts_obj_scaled[,c("observed", "brazil_counts")]) +
  xlab("Year") + 
  ylab("Normalized Counts") +
  scale_color_discrete(name = "Counts", labels = c("US Case Count", "Brazil Count")) +
  labs(title = "Weekly Zika Case Counts in the US and Brazil, Over Time")
```

<p> **Observations:** We see that the Zika cases in Brazil peak in early 2016. This is before the peak in the United States, and so, case counts from Brazil, lagged by a few weeks, could potentially be useful in the forecasting of cases in the US.</p>


```{r cases_tweets}
autoplot(ts_obj_scaled[,c("observed", "tweet_count")]) +
  xlab("Year") + 
  ylab("Normalized Counts") +
  scale_color_discrete(name = "Counts", labels = c("US Case Count", "Tweet Count")) +
  labs(title = "Weekly Zika Case Counts in the US and Weekly Tweek Count, Over Time")
```

<p> **Observations:** We see that the Zika cases in the United States align fairly well with the number of weekly tweets containing Zika-related keywords. Theser is a small spike seen in the earlier weeks of 2016, that might correspond to the outbreak of the virus in Brazil.</p>

```{r cases_reddit}
autoplot(ts_obj_scaled[,c("observed", "submission_count", "comment_count")]) +
  xlab("Year") + 
  ylab("Normalized Counts") +
  scale_color_discrete(
    name = "Counts", 
    labels = c("US Case Count", "Reddit Submission Count", "Reddit Comment Count")
    ) +
  labs(
    title = "Weekly Zika Case Counts in the US, Weekly Reddit Submission Count, and Reddit Comment Count, Over Time"
    )
```

<p> **Observations:** The number of reddit submissions and comments pertaining to the Zika virus also follows trends similar to the US case counts. However, an interesting thing to note is that, given that the reddit data is not restricted to users in the United States, the Zika-related activity shows a much higher peak around the time the virus outbroke in Brazil compared to the chatter on Twitter, that was limited to the US.</p>

```{r cases_accounts}
autoplot(ts_obj_scaled[,c("observed", "ph_account_counts")]) +
  xlab("Year") + 
  ylab("Normalized Counts") +
  scale_color_discrete(
    name = "Counts", 
    labels = c("US Case Count", "Count of Tweets from Public Health Accounts")
    ) +
  labs(
    title = "Weekly Zika Case Counts in the US, Weekly Number of Tweets from Public Health Accounts, Over Time"
    )
```

<p> **Observations:** Although there weren't too many tweets shared by public health accounts, upon normalization, the chatter amongst thepublic health community adheres fairly well to the US case count trends.</p>

```{r count_tweet_keywords}
autoplot(ts_obj_scaled[,c("observed", "tk_zika", "tk_mosquito", "tk_flavivirus", "tk_zikv", "tk_aedes")]) +
  xlab("Year") + 
  ylab("Normalized Counts") +
  scale_color_discrete(
    name = "Counts", 
    labels = c(
      "US Case Count",
      "Occurances of the word 'zika'", 
      "Occurances of the word 'mosquito'",
      "Occurances of the word 'flavivirus'",
      "Occurances of the word 'zikv'",
      "Occurances of the word 'aedes'"
      )
    ) +
  labs(
    title = "Weekly Zika Case Counts in the US, Weekly Keyword Occurances in Tweets, Over Time"
    )
```

<p> **Observations:** Rarely occuring keywords like 'flavivirus' and 'aedes' seem to follow very noisy trends. The more abundant ones such as 'zika' and 'mosquito' follow trends similar to those seeen for overall tweet counts. This might be because a majoirty of the Zika-related tweets contain those two words.</p>

```{r count_subreddit_submissions}
autoplot(ts_obj_scaled[,c("observed", "num_science_submissions", "num_zika_submissions", "num_health_submissions")]) +
  xlab("Year") + 
  ylab("Normalized Counts") +
  scale_color_discrete(
    name = "Counts", 
    labels = c(
      "US Case Count",
      "Submissions made to the 'science' subreddit", 
      "Submissions made to the 'zika' subreddit", 
      "Submissions made to the 'health' subreddit"
      )
    ) +
  labs(
    title = "Weekly Zika Case Counts in the US, Weekly Submissions in Specific Subreddits, Over Time"
    )
```
<p> **Observations:** The number of reddit submissions made to the 'science' subreddit seems to **precede** the trend the US case counts is about to follow. This suggests, that a lagged predictor for the number of 'sicence' submissions might be useful in predicting US case counts.</p>

#### 1.4 Determine whether there is Autocorrelation and/or Cross-correlation

<p> Now we will visualize the correlation between various lags within and across timeseries. We will perform first differencing on our data before plotting these auto and cross correlation plots to prevent</p>

##### 1.4.a Autocorrelation

<p>We will use autocorrelation plots to determine case counts from how many weeks prior is most correlated to the 'present' number of case counts. In other words, this will help us determine whether we can leverage past case counts to predict future case counts. To check for autocorrelation, we will first perform a qualitative scan of our first differenced Weekly US cases counts.</p>

```{r acf}
ggAcf(diff(forecast_df$observed), na.action = na.omit) +
  labs(title = "Autocorrelation Function Plot for Differenced US Zika Case Counts")

ggAcf(diff(forecast_df$observed), na.action = na.omit, type = "partial") +
  labs(title = "Partial Autocorrelation Function Plot for Differenced US Zika Case Counts")
```

<p> **Observations:** Case counts from  *1*, *2*, and *3* weeks ago seem to be most correlated with the 'current' case count. This is suggests that lag terms of 1, 2, and 3 might be worth trying out.

##### 1.4.b Cross-correlation

<p> The timeseries plots that showed how the trends of our other features compared to the observed number of weekly cases of Zika in the US suggested that there might be some correlation between these other timeseries and the US Zika case count time series. To check for lagged correlations between the US Zika case counts and the other (time dependent) features in our dataset, we will check the cross-correlation. Based off of our earlier timeseries plots, it seemed like the following features could potentially be cross correlated with the Weekly Case Counts of the zika Virus in the US:

* Brazil Case Counts
* Tweet Counts
* Reddit Submissions/Comments
* Number of Tweets from Public Health Accounts

```{r brazil_observed}
ggCcf(x = diff(forecast_df$observed), y = diff(forecast_df$brazil_counts), na.action = na.omit) +
  labs(title = "Cross Correlation Function Plot Between Differenced US Zika Case Counts and Brazil Case Counts")
```

<p>**Observations:** It seems like case counts in Brazil reported 20 weeks (or 5 months) earlier have some correlation with the current number of cases in the US.</p>

```{r tweets_observed}
ggCcf(x = diff(forecast_df$observed), y = diff(forecast_df$tweet_count), na.action = na.omit) +
  labs(title = "Cross Correlation Function Plot Between Differenced US Zika Case Counts and Tweet Counts")
```

<p>**Observations:** We see both positive and negativ lag terms that are significant for Tweet counts. The negative lag terms suggest that the Tweets appear __after__ the cases are reported. However, it also appears that Tweet counts from 3 or 6 weeks before may be relevant in predicting the number of reported cases in the current week.</p>

```{r}
ggCcf(x = diff(forecast_df$observed), y = diff(forecast_df$submission_count), na.action = na.omit) +
  labs(title = "Cross Correlation Function Plot Between Differenced US Zika Case Counts and Reddit Submissions")
```

<p>**Observations:** It appears that the number of reddit submissions from 14 weeks prior might be relevant in preicting reported cases of Zika.</p>

```{r}
ggCcf(x = diff(forecast_df$observed), y = diff(forecast_df$ph_account_counts), na.action = na.omit) +
  labs(title = "Cross Correlation Function Plot Between Differenced US Zika Case Counts and Number of Tweets from Public Health Accounts")
```


<p>**Observations:** The number of tweets made by Public Health affiliated accounts seem to be highly cross-correlated with US case counts for lag terms of 2, 4, and 6. The recurrance of a significant corss-correlation for every two weeks into the past is suggestive of a peak and then fall. So, it seems like the number of tweets from two weeks ago might be most useful for Zika case count forecasting.</p>


## 2. Modelling

<p> Now that we have established a reasonable understanding of our data and how various features are/could be associated with our outcome variable, Weekly Reported Cases of Zika in the US, we can begin trying out different models.</p>

### Purely Autoregressive Models
#### ARIMA(1,1)
```{r}
ar_1 <- Arima(ts_obj[53:104,"observed"], order=c(1, 1, 0))
f1 <- forecast(ar_1)
summary(ar_1)
```

#### ARIMA(2,1)
```{r}
ar_2 <- Arima(ts_obj[53:104,"observed"], order=c(2, 1, 0))
f2 <- forecast(ar_2)
summary(ar_2)
```

#### ARIMA(3,1)
```{r}
ar_3 <- Arima(ts_obj[53:104,"observed"], order=c(3, 1, 0))
f3 <- forecast(ar_3)
summary(ar_3)
```

<p> Amongst the three, purely autoregressive models we tried, the models with lags of 2 and 3 weeks seem to perform better than the model where the lag is set to 1 week. The AIC value is the smallest for the `ARIMA(2, 1)` model, while the root mean squared error (RMSE) is lowest for the `ARIMA(3,1)` model. The RMSE can be interpretted as the number of cases our prediction was off by on average.</p>

<p>We decided to proceed to use the Weekly Zika Case Counts for time __T-3__ to predict the cases at time __T__</p>

#### Autoregressive Models with (lagged) covariates

<p>Having selected the autoregressive component model, we can now experiment with additional covariates and their corresponding lags. Based on the timeseries and cross-correlation plots we explored earlier, the features which seem most likely to be useful in explaining the variance in weekly US case counts (our response) are listed with their respective lags below:</p>

* Weekly cases in Brazil
* Weekly Reddit submission count
* Weekly Tweet count
* Weekly number of Tweets shared by Public Health related accounts
* Weekly count of submissions made to Science subreddit

<p>We will first experiment with how these different covariates influence the RMSE and improve or worsen our predictive performance.</p>

#### ARIMA(3,1) + Brazil Case Count
```{r}
ar_brazil <- Arima(
  ts_obj[53:104,"observed"],
  xreg = ts_obj[53:104, c("brazil_counts")], 
  order=c(3, 1, 0)
  )
f_brazil <- forecast(
  ar_brazil, 
  xreg = ts_obj[53:104, c("brazil_counts")]
  )
summary(ar_brazil)
```


#### ARIMA(3,1) + Tweet Count
```{r}
ar_tweet <- Arima(
  ts_obj[53:104,"observed"],
  xreg = ts_obj[53:104, c("tweet_count")], 
  order=c(3, 1, 0)
  )
f_tweet <- forecast(
  ar_tweet, 
  xreg = ts_obj[53:104, c("tweet_count")]
  )
summary(ar_tweet)
```

#### ARIMA(3,1) + Reddit Science Submissions
```{r}
ar_sci_submission <- Arima(
  ts_obj[53:104,"observed"],
  xreg = ts_obj[53:104, c("num_science_submissions")], 
  order=c(3, 1, 0)
  )
f_sci_submission <- forecast(
  ar_sci_submission, 
  xreg = ts_obj[53:104, c("num_science_submissions")]
  )
summary(ar_sci_submission)
```

#### ARIMA(3,1) + Public Health Account Tweets
```{r}
ar_ph_account <- Arima(
  ts_obj[53:104,"observed"],
  xreg = ts_obj[53:104, c("ph_account_counts")], 
  order=c(3, 1, 0)
  )
f_ph_account <- forecast(
  ar_ph_account, 
  xreg = ts_obj[53:104, c("ph_account_counts")]
  )
summary(ar_ph_account)
```

<p>From the above models, where all we changed was the covariate included, it seems like the ARIMA(3,1) model with Tweet count and Public Health Tweet count had the lowest AIC values of __543.04__ and __544.74__, respectively. Corresponding RMSE values for these two models is also relatively lower than the other models tried out in this section.</p>

<p> It will be interesting to see if we can improve our prediction by incorporating both these covariates into a single model</p>


#### ARIMA(3,1) + Tweet Count + Public Health Account Tweets
```{r}
ar_tweet_ph_account <- Arima(
  ts_obj[53:104,"observed"],
  xreg = ts_obj[53:104, c("tweet_count", "ph_account_counts")], 
  order=c(3, 1, 0)
  )
f_tweet_ph_account <- forecast(
  ar_tweet_ph_account, 
  xreg = ts_obj[53:104, c("tweet_count", "ph_account_counts")]
  )
summary(ar_tweet_ph_account)
```

<p>This model that incorporates both, the Tweet Count and Number of Tweets shared by Public Health accounts has the lowest RMSE value we've observed so far (**44.086**)!</p>

<p>Now we will experiment with the lags of these shortlisted features to see if our model can be made even better.</p>

##### Setting up some lagged covariates.
```{r lag_terms, echo=TRUE}
lagged_predictors <- cbind(
  lagged_brazil_counts = stats::lag(ts_obj[,"brazil_counts"], -20), # lag of 8 because cases in Brazil began to appear about 2 months prior to when they started popping up in the US
  lagged_ph_accounts = stats::lag(ts_obj[,"ph_account_counts"], -2), # based on CCF
  lagged_tweet_counts = stats::lag(ts_obj[, "tweet_count"], -5), # based on CCF
  lagged_submission_counts = stats::lag(ts_obj[, "submission_count"], -14) # based on CCF
)
```


#### ARIMA(3,1) + Tweet Count + Public Health Account Tweets + Lagged Brazil Case Counts + Lagged Reddit Submissions
```{r}
ar_tweet_reddit_ph_account_brazil <- Arima(
  ts_obj[53:104,"observed"],
  xreg = cbind(
    ts_obj[53:104, c("tweet_count", "ph_account_counts")],  
    brazil_cases=lagged_predictors[53:104, "lagged_brazil_counts"],
    reddit_submissions=lagged_predictors[53:104, "lagged_submission_counts"]
    ), 
  order=c(3, 1, 0)
  )
f_tweet_reddit_ph_account_brazil <- forecast(
  ar_tweet_reddit_ph_account_brazil, 
  xreg = cbind(
    ts_obj[53:104, c("tweet_count", "ph_account_counts")],  
    brazil_cases=lagged_predictors[53:104, "lagged_brazil_counts"],
    reddit_submissions=lagged_predictors[53:104, "lagged_submission_counts"]
    )
  )
summary(ar_tweet_reddit_ph_account_brazil)
```

<p>Looks like adding in the lagged Brazil case counts and and Reddit submissions improved our model by further reducing the RMSE down to __42.93822__!</p>


So here is our final model:<br>

$Y_t = \beta_0+\beta_1*Y_{t-1}+\beta_2*Y_{t-2}+\beta_3*Y_{t-3}+\beta_4*X_1+\beta_5*X_2+\beta_6*X_3+\beta_7*X_4$ <br>

Where, <br>
$Y_t$ is the number of cases of Zika in the US in week $t$ <br>
$Y_t-1$ is the number of cases of Zika in the US in week $t-1$ <br>
$Y_t-2$ is the number of cases of Zika in the US in week $t-2$ <br>
$Y_t-3$ is the number of cases of Zika in the US in week $t-3$ <br>
$X_1$ is the number of Zika related Tweets shared in week $t$ <br>
$X_2$ is the number of Zika related Tweets shared by Public Health Accounts the US in week $t$ <br>
$X_3$ is the number of cases of Zika in Brazil in week $t-20$ <br>
$X_4$ is the number of Zika related submissions made to Reddit in week $t-14$ <br>


# 3. Evaluation

<p>We evaluate the performance of our final model by:</p>
1. Visually assessing how well the predicted trend fits the actual trend
2. Computing the one-step-ahead prediction error

### 1. Qualitiative Assessment

```{r}
# Visualize Fitted vs Actual
predictions <- as.data.frame(cbind(
  week = 1:52,
  actual = ts_obj[53:104, c("observed")],
  pure_arima = f3$fitted,
  tweets_only = f_tweet$fitted,
  final_model = f_tweet_reddit_ph_account_brazil$fitted
  ))


predictions %>%
  gather(key = "Model", value = "Prediction",  c(actual, pure_arima, tweets_only, final_model)) %>%
  ggplot(aes(x = week, y = Prediction, color = Model)) +
  geom_line(size = 1) + 
  scale_color_discrete(
    name = "Models", 
    labels = c(
      "actual", 
      "ARIMA(3,1)", 
      "ARIMA(3, 1) + Tweet Count", 
      "ARIMA(3,1) + Tweet Count + PH Tweet Count + Brazil Case Count + Reddit Submission Count"
      )
    )
```

<p>It seems like all the models are adhering to the true case count trend in 2016 (for which both actual and predicted values are plotted). However, they seem to be underestimating the total number of cases. Since the difference in prediction error across these four models was not that large, it makes sense that none of them follow an absurd trend that deviates vastly from the actual counts.</p>


### 2. Evaluating Metrics

<p> The metrics we compared to assess the various models we tried were:</p>
* Root Mean Squared Error (RMSE) <br>
* A Modified Version of the $R^2$ <br>
* Akaike's Information Criterion (AIC) <br>

#### RMSE

<p>The Root Mean Squared Error for each model was computed as follows:</p>

$RMSE = \sum{\sqrt{(\hat{y_{t+h|t}} - y_{t+h})^2/}/n}$<br>

<p> To compute the __one step ahead__ prediction/error, we set $h = 1$. We interpret the RMSE as the average number of case counts our prediction was off by.</p>

#### Modified $R^2$

<p>We computed the $R^2$ values for the ARIMA models as the correlation between the fitted and the predicte values. We interpret this modified version of the $R^2$ as the total approximate variance in the number of predicted weekly case counts explained by the model.</p>

<p>All the evaluation metrics, except the modified $R^2$ are printed in the model summaries above. Here are the values of the modified $R^2$ for the models we tried:</p>

```{r}
cor(fitted(ar_1), ts_obj[53:104,"observed"])^2


cor(fitted(ar_tweet), ts_obj[53:104,"observed"])^2


cor(fitted(ar_tweet_reddit_ph_account_brazil), ts_obj[53:104,"observed"])^2

```



# 4. Prediction

<p>Given the number of Tweets shared, Tweets made by public health affiliated accounts, case counts of Zika reported 20 weeks ago, and number of Zika related submissions made 14 weeks ago, we can predict the number of potential occurances of the Zika Virus in the United States in the current week.</p>

### Example:

```{r}
week_75_predicted <- f_tweet_reddit_ph_account_brazil$fitted[75-52]

week_75_actual <- ts_obj[75, "observed"]

paste("Observed", week_75_actual)
paste("Predicted", week_75_predicted)
```


